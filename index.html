<!DOCTYPE html>

<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Aerosensorfusion</title>
  
  <link rel="icon" type="image/x-icon" href="./assets/favicon.ico"/>
  
  <link rel="stylesheet" href="./style/ieee_webpage.css">
  
  

  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Condensed&family=Roboto:wght@300&display=swap" rel="stylesheet">
  
  <link rel="stylesheet" href="./style/font-awesome_4.7.0.min.css">
  
</head>

<body>


<h1>AEROSENSORFUSION PROJECT</h1>

  <div>
  
    <div>
	  <figure>
	    <a href="" style="text-decoration: none;">
	      <!--img src="./assets/teaser_1.svg" alt="alt1" style="max-width:100%;"-->
	    </a>
	  </figure>
	</div>

	<p>During an aerodynamic design evaluation effort several different types of data are collected.
The task for the aerodynamicist is to formulate an explanation of the observed behavior that
takes into consideration the features shown in this multimodal data, and make decisions based
on it. The fusion of data features into a coherent explanation of the observed behaviour is
usually done solely in the mind of the expert. This paper presents a web-based approach that
reduces the burden placed on the expert by: (1) allowing image based data, for example oil or
flow-visualisation paint images to be visually fused with relevant CFD and experimental data,
such as area traverse measurements, in a common 3D coordinate system, and (2) supporting
collaborative data analysis and capture of experts’ observations by adding 3D annotation
shapes, and text comments. The web-based implementation allows for collaborative work, and
is portable between commercial electronic devices, such as smartphones and tablets, which in
turn allow portability of the analysis location, and allow the aerodynamicist to easily capture
additional image-based data using the devices’ cameras.</p>


<p>Alternately, the project can be seen as a 3D scientific data visualisation analogue of videos shared online. In the ASME GT 2022 "Industrializing Terabytes for Propulsion and Power" plenary session a desire for shareable open datasets, and ability to capture and transfer insights between engineers effectively was expressed. Focus was put on the scientific community to provide these solutions, and, as many attendees lamented afterwards, not many specific ideas were put forward. This project can be seen to address the challenges posed by the plenary members by providing (1) a web-based environment to share ready made interactive 3D design, simulation, and experimental measurement data visualisations, and (2) the tools to capture insights and annotations collaboratively within hte 3D environment.</p>


<p>Below the individual components of the proposed environment are discussed in dedicated demos. Clicking on hte image takes you to the demo itself.</p>

<!--

FOR SOME THINGS THE DATA WILL HAVE TO BE LOADED INTO THE BROWSER ANYWAY, LIKE INTERACTIVE EXTRACTION OF LIFT DISTRIBUTIONS, AND BOUNDARY LAYER VELOCITY PROFILES.

BOUNDARY LAYER: Could be interesting to see the boundary layer thinckness calculated for the entire wing. And maybe seed the streamlines such that the boundary layer flows are visible?

Some components have analogous solutions already implemented within ParaView, but the drawback of ParaView is that it is not web-based, and some of its features, such as streamline sampling, could be improved. This project proposes to view ParaView as a staging environment before it is pu

ParaView isn't online, and features have some issues. ParaView is staging environment before publishing.



-->


  </div>


<h2><span>Annotations</span></h2>

  <div>
    <div style="max-width: 900px;">
	  <figure>
	    <a href="./annotations.html" style="text-decoration: none;">
	      <img src="./assets/teaser_annotations.jpg" alt="alt1">
	    </a>
	  </figure>
	</div>

	<p>The demo is set in space because the geometry creation was easy. The user can position yellow glowing annotation spheres on top of the box-satellites by clicking on them. Positioning of spheres in free space is not activated in this demo. By activating the sponge button the user can enter the mode in which clicking on hte box satellites removes the spheres.</p>

	<p>To adjust the depth/radius of individual spheres the user must first select the sphere to adjust. By clicking on a sphere its glow turns red indicating that it is selected. The sliders in the top right corner work as incremental controls - grabbing the handle and moving it left adds a negative increment to the relevant property for each change in the input state. This allows for coarse adjustments in the extreme position, and fine adjustments near the center. After letting go the controls re-center.</p>
  </div>

<h2><span>Streamlines</span></h2>

  <div>
    <div style="max-width: 900px;">
	  <figure>
	    <a href="./streamlines.html" style="text-decoration: none;">
	      <img src="./assets/teaser_streamlines.jpg" alt="alt1"-->
	    </a>
	  </figure>
	</div>
	
	
	<p>This demo uses the delta wing data collected in the Flow Visualisation ExA. CFD is one of the data streams, and to capture knowledge about it some of it must be visualised. This could be a good opportunity to showcase some of Thanassis' work also. It takes some time to load in the streamline data.</p>

	<p>The movement of the 'streamlets' (streamline particle) encodes local flow direction, the color encodes the local Mach number, the length encodes the velocity magnitude. More specifically, the length is the distance that the leading point of the streamlet travelled in the last five re-renders. We've seen a similar visualisation before: a global wind visualisation app PolarGlobe (in the PPD report). Similarly ParaView supports drawing of streamlets. The disadvantage of both the PolarGlobe and ParaView approaches is that for every camera change the seeds need to be reinitialised, and the trace is lost. Furthermore, PolarGlobe selects points in the domain and just adds the local velocity times a delta time to the current point. The delta time is used to control the speed of the animation, but changing it means that the streamlines potentially change also - the authors themselves noted this in their paper.</p>

	<p>My approach relies on ParaView to calculate some streamlines, which I save into a csv file, and subsequently load into the JavaScript environment. The animation is created by only rendering n-points (n=5) at once, and sequentially changing which n vertices are connected with the line. In contrast to the PolarGlobe the vertices to be drawn are on a fixed line, therefore the shape of the line is preserved regardless of animation speed.</p>

	<p>The vertices to be drawn are re-set on every render draw to create the animation. However, camera navigation events trigger additional render calls, which means that camera navigation accelerates the animation. To correct for this the streamline updating can be limited to one draw for a given timestep.</p>

	<p>ParaView does not export points along streamlines at the same integration timesteps - this means that the velocity encoding as length is not really true, as streamlets with larger dt between their constitutive point will artificially appear faster. To address this the ParaView csv data can be re-interpolated to find points comparable timesteps apart.</p>


	<p>Another approach is to prescribe the global integration time to all lines, and allow the closest timestep to be selected as the first point of the streamlet. Then a common time offset can be used to find the last streamlet point. This will still not accurately capture integrated velocity as length, because of the need to find the closest timestep, which depends on discretisation.</p>

	<p>Controlling the animation speed. Using the debounced indexing approach the minimum speed relies on the discretisation - if the streamlet refresh rate is too low the streamlets will not move smoothly. Furthermore, the maximum speed is also limited by the discretisation - for very high streamline refresh rates the streamlines are updated every render call, which just advances the index by one, hence the discretisation controls the maximum speed.</p>

	<p>Another consideration is the framerate, which is not always consistent. Therefore to be able to track particles in real time the time prescription method is more applicable. As mentioned above this also controls the speed at which the streamlet advances through the domain. By prescribing two timesteps the start and finish of the streamlet can be defined, which can allow the length of the streamlet to be better controlled. Discretisation still plays a role, as it determines the resolution.</p>

	<p>Streamlines in ParaView were created using the sphere seed geometry: ParaView selects n random intitial streamline positions within the sphere, and starts moving down and upstream of these points to find the lines. Because the streamlines all start relatively close together the streamlets also start together, and move through the domain togehter. Although such a visualisation may be useful, to visualise the entire flow field with moving streamlines the streamlets need to be offset.</p>

	<p>Fade in, and fade out are controlled by controlling the indexing, dynamically changing the number of vertices to draw from 0 at the beginning to n, and vice versa. An alternate approach is to just find the start/end index based on the timestamps. Then the finding of the correct times handles the fade in and out effects.</p>
 </div>
	
<h2><span>Decals</span></h2>

 <div>
    <div style="max-width: 900px;">
	  <figure>
	    <a href="./decals.html" style="text-decoration: none;">
	      <img src="./assets/teaser_decals.jpg" alt="alt1"-->
	    </a>
	  </figure>
	</div>
	
	
	<p>Decals are added into the scene as additional scene objects, specifically meshes comprised of a 'DecalGeometry' object, and a material object. DecalGeometry takes as the input the support mesh, a position, orinetation, and size. Based on the latter three parameters a cutout of the support mesh is extracted as the DecalGeometry, and the material is applied to it.</p>
	
	
	<p><b>Why is a dark triangle placed on the other side?</b> For thin geometries the cutting of the support geometries can result in vertices from both sides being selected. Selecting a smaller z component of the size removed the additional decal on the opposing side.</p>
	
	<p>Maybe pushDecalVertex needs to be updated? The idea is that the cutout of the mesh is too big, and it takes into account the other side of the airfoil also. To prevent the other surface being added we need to exclude the vertices with the normal in hte same general direction as the view vector.</d>
	
	<p>On the pressure side the decals are always black, and on the suction side they are colorful. This holds true even if the decal is initially placed on hte PS. Is this a vertex normal problem? The aiming line gets it's normal from the point on the surface, so the normals should be ok?</p>
	
	
	<p><b>Decal preview, placement, orinetation, and size:</b> ideally there would be a preview when positioning hte decal, and afterwards the decal should be movable to allow adjustments to the positioning and size. In this approach the clicking positions the decal roughly, and incremental sliders position it finely. However, the decals are cutouts of the supporting geometry, and to move them the corresponding cutout needs to be provided. Will this be fast enough to be interactive?</p>
	
	
	
 </div>	
	
<h2><span>Pictures and Videos</span></h2>

 <div>
    <p>NOT BEGUN YET.</p>
 </div>



<h2>Future Work Ideas</h2>

  <div>
	<p>The application we are making can also be seen as the 3D small multiple rendering inset - much like the unsteady turbine example was a 2D inset. A large part of that work was data handling, and in this project we have the time to attempt to use compressed data that is uncompressed on the GPU. Thanassis already worked on extracting only subsets of relevant 3D data. In addition we could also attempt to perform data tiling. This section of the title could be framed as a challenge to find the largest CFD simulation possible to visualise in the browser. Again we can discuss the idea of 4GB per screen area.</p>


	<p>One apparent aspect of ParaView animated streamlets is that they occupy the entire domain, and that the user cannot (is this true?) control the seeding. Streamlet seeding is a similar problem to sampling, e.g. selecting points for traverse measurements. GPR (Gaussian Process Regression) is a common statistical technique that can be applied to determine the locations with the highest/lowest uncertainties, which can help identifiy valuable sampling points. GPR can therefore be used to place streamlets in the most uncertain points of the velocity field, which are the domain points with the largest velocity changes. Maybe a good first approach is to create a model in Matlab and load the line selection in, as opposed to doing it on the fly.</p>


	<p>Try to implement virtual smoke visualisation by seeding particles. The particles move along streamlines, but implicitly - their path is influenced at every step. By adjusting their weight, and subsequently inertia the impact of hte differences in fluid properties (smoke vs air) could be assessed. Similarly: by adding bounce-stick mechanics to the seeding particles could be allowed to deposit themselves on the surface. By associating a potential flow doublet of a specific strength with the particle could the flow-field velocity be adjusted for following particles without recalculating the base CFD? The potential flow approach could also allow particles to be modelled as something else than a sphere.</p>
  </div>

<h2><span>Authors</span></h2>

  <div>

	<ol class="no-list-style">
	  <li>
		<div>
		  <h4 class="author-name">
			<span slot="name">Aljaz Kotnik</span>
		  </h4>
		  <div>
			<span slot="affiliation">University of Cambridge<br>Whittle Laboratory</span>
		  </div>
		  <div>
			<span>
			  <i class="fa fa-github"></i>
			  <a href="https://github.com/aljazkotnik" target="_blank" slot="github">aljazkotnik</a>
			</span>
		  </div>
		</div>
	  </li>
	  
	  <li>
		<div>
		  <h4 class="author-name">
			<span slot="name">Graham Pullan</span>
		  </h4>
		  <div>
			<span slot="affiliation">University of Cambridge<br>Whittle Laboratory</span>
		  </div>
		  <div>
			<span>
			  <i class="fa fa-globe"></i>
			  <a href="https://whittle.eng.cam.ac.uk/lab/team/graham-pullan/" target="_blank" slot="website">Graham @ Whittle Laboratory</a>
			</span>
			<span>
			  <i class="fa fa-twitter"></i>
			  <a href="https://twitter.com/grahampullan" target="_blank" slot="twitter">grahampullan</a>
			</span>
			<span>
			  <i class="fa fa-github"></i>
			  <a href="https://github.com/grahampullan" target="_blank" slot="github">grahampullan</a>
			</span>
		  </div>
		</div>
	  </li>
	</ol>

  </div>
  
  
<h2><span>Miscellaneous</span></h2>
  <div>
    
	<p>Ultimately the entry point for the user is the dbslice dash. The user filters out subsets, and observes high level data behavior. Then through the data levels they arrive to the detailed data. At the detailed data the actual flow insights are gathered.</p>

	<p>A design, or concept exploration process is done step by step, and new data is generated every step. The web based dbslice available to users should have an option to upload new data on-the-go. Maybe the metadata can be stored in a background SQL database. An initial query can be made to retrieve all the tasks, at which point the crossfilter indexing is set up to support the interactions.</p>

	<p>Datetime of the simulation should be a parameter in dbslice, that way new users can see the progression of the designs.</p>
	
  </div>

</body>

</html>
